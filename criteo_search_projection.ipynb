{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import criteo_search2\n",
    "from net import Net_embedding\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from utils import AverageMeter\n",
    "\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = criteo_search2.CriteoSearchDataset(\"../data/\" + 'Criteo_Search.txt')\n",
    "seed = 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset length:  1316781 test_dataset length:  329196 device:  cuda\n"
     ]
    }
   ],
   "source": [
    "train_length = int(len(dataset) * 0.8)\n",
    "test_length = len(dataset) - train_length\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(\n",
    "            dataset, (train_length, test_length), generator=torch.Generator().manual_seed(seed))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('train_dataset length: ', len(train_dataset), 'test_dataset length: ', len(test_dataset), 'device: ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_optimal_interval2(interval_freq, node, epsilon, delta):\n",
    "    \n",
    "    # Step 3: RPWithPrior i.e. Algorithm 1 in paper\n",
    "    k = len(interval_freq)\n",
    "    fmax = 0 # max value of f\n",
    "    for i in range(k):\n",
    "        for j in range(i+1, k):\n",
    "            h = interval_freq[i] * node[i+1] + \\\n",
    "                torch.sum(interval_freq[i+1:j] * (node[i+2:j+1] - node[i+1:j])) - \\\n",
    "                    interval_freq[j] * node[j]\n",
    "            c1 = 2 * delta * interval_freq[i] - math.exp(-epsilon) *  h\n",
    "            slope = math.exp(-epsilon) * (interval_freq[j] - interval_freq[i])\n",
    "            \n",
    "            d11 = slope * node[j] -c1\n",
    "            d12 = slope * node[j+1] - c1\n",
    "            \n",
    "            c2 = 2 * delta * interval_freq[j] - math.exp(-epsilon) * h\n",
    "            \n",
    "            d21 = -slope * node[i] + c2\n",
    "            d22 = -slope * node[i+1] + c2\n",
    "            e1 = c1 / slope\n",
    "            e2 = c2 / slope\n",
    "            \n",
    "            A1max = node[i]\n",
    "            A2max = node[j]\n",
    "            h1 = (h + interval_freq[j] * A2max - interval_freq[i] * A1max) / (\n",
    "                2 * delta+math.exp(-epsilon)*(A2max - A1max) )\n",
    "            if fmax < h1:\n",
    "                fmax = h1\n",
    "                A1 = A1max\n",
    "                A2 = A2max\n",
    "            \n",
    "            # (n_i,n_{j+1})\n",
    "            A2max = node[j+1]\n",
    "            h1 = (h + interval_freq[j] * A2max - interval_freq[i] * A1max) / (\n",
    "                2 * delta+math.exp(-epsilon)*(A2max - A1max) )\n",
    "            if fmax < h1:\n",
    "                fmax = h1\n",
    "                A1 = A1max\n",
    "                A2 = A2max\n",
    "                \n",
    "            # (n_{i+1},n_{j+1})\n",
    "            A1max = node[i+1]\n",
    "            h1 = (h + interval_freq[j] * A2max - interval_freq[i] * A1max) / (\n",
    "                2 * delta+math.exp(-epsilon)*(A2max - A1max) )\n",
    "            if fmax < h1:\n",
    "                fmax = h1\n",
    "                A1 = A1max\n",
    "                A2 = A2max \n",
    "                \n",
    "            # (n_{i+1},n_j)\n",
    "            A2max = node[j]\n",
    "            h1 = (h + interval_freq[j] * A2max - interval_freq[i] * A1max) / (\n",
    "                2 * delta+math.exp(-epsilon)*(A2max - A1max) )\n",
    "            if fmax < h1:\n",
    "                fmax = h1\n",
    "                A1 = A1max\n",
    "                A2 = A2max\n",
    "                \n",
    "                \n",
    "            if d21 * d22 < 0:\n",
    "                # (e_2,n_j)\n",
    "                A1max = e2\n",
    "                A2max = node[j]\n",
    "                \n",
    "                h1 = (h + interval_freq[j] * A2max - interval_freq[i] * A1max) / (\n",
    "                    2 * delta+math.exp(-epsilon)*(A2max - A1max) )\n",
    "                if fmax < h1:\n",
    "                    fmax = h1\n",
    "                    A1 = A1max\n",
    "                    A2 = A2max\n",
    "                \n",
    "                # (e_2,n_{j+1})\n",
    "                A2max = node[j+1]\n",
    "                \n",
    "                h1 = (h + interval_freq[j] * A2max - interval_freq[i] * A1max) / (\n",
    "                    2 * delta+math.exp(-epsilon)*(A2max - A1max) )\n",
    "                if fmax < h1:\n",
    "                    fmax = h1\n",
    "                    A1 = A1max\n",
    "                    A2 = A2max\n",
    "            if d11 * d12 < 0:\n",
    "                # (n_i,e_1)\n",
    "                A1max = node[i]\n",
    "                A2max = e1\n",
    "                \n",
    "                h1 = (h + interval_freq[j] * A2max - interval_freq[i] * A1max) / (\n",
    "                    2 * delta+math.exp(-epsilon)*(A2max - A1max) )\n",
    "                if fmax < h1:\n",
    "                    fmax = h1\n",
    "                    A1 = A1max\n",
    "                    A2 = A2max\n",
    "                \n",
    "                # (n_{i+1}, e_1)   \n",
    "                A1max = node[i+1]\n",
    "                \n",
    "                h1 = (h + interval_freq[j] * A2max - interval_freq[i] * A1max) / (\n",
    "                    2 * delta+math.exp(-epsilon)*(A2max - A1max ) )\n",
    "                if fmax < h1:\n",
    "                    fmax = h1\n",
    "                    A1 = A1max\n",
    "                    A2 = A2max  \n",
    "                    \n",
    "            if  d11 * d12 < 0 and d21 * d22 < 0:  \n",
    "                # (e_2,e_1)\n",
    "                A1max = e2\n",
    "                A2max = e1      \n",
    "                h1 = (h + interval_freq[j] * A2max - interval_freq[i] * A1max) / (\n",
    "                    2 * delta+math.exp(-epsilon)*(A2max - A1max ))\n",
    "                if fmax < h1:\n",
    "                    # fmax = h1\n",
    "                    A1 = A1max\n",
    "                    A2 = A2max\n",
    "    return A1, A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RPWithPrior3(train_loader, device, epsilon=0.1, delta=0.1):\n",
    "    # Step 1: obain the prior from prev stage model\n",
    "    for i, (x, z, y) in enumerate(train_loader):\n",
    "        x, z, y = x.to(device), z.to(device), y.to(device)\n",
    "        tartget = y\n",
    "\n",
    "        if i == 0:\n",
    "            x_sets = x\n",
    "            z_sets = z\n",
    "            y_sets = y\n",
    "        else:\n",
    "            x_sets = torch.cat((x_sets, x), 0)\n",
    "            z_sets = torch.cat((z_sets, z), 0)\n",
    "            y_sets = torch.cat((y_sets, y), 0)\n",
    "            \n",
    "        target_sets = y_sets\n",
    "\n",
    "    # calculate the statistics of prior\n",
    "    target_mean = target_sets.mean()\n",
    "    target_std = target_sets.std() \n",
    "    \n",
    "    # Step 2: calculate the histogram of prior \n",
    "    # calculate the value in each interval of the histogram\n",
    "    k0 = ((torch.min(target_sets) - target_mean) / target_std ).floor().int().item()\n",
    "    k1 = ((torch.max(target_sets) - target_mean) / target_std ).ceil().int().item()\n",
    "    k = k1 - k0\n",
    "\n",
    "    node = torch.zeros(k+1) # node in paper x_0...x_k\n",
    "    interval_freq = torch.zeros(k) # value in each interval for histogram\n",
    "\n",
    "    # calculate the relative frequency(probability) of each interval\n",
    "    for i in range(k0, k1):\n",
    "        if i == k0:\n",
    "            node[i-k0] = torch.min(target_sets)\n",
    "        else: \n",
    "            node[i-k0] = target_mean + i * target_std\n",
    "        if i < k1 - 1:\n",
    "            in_range = (target_sets - target_mean >= i * target_std) & \\\n",
    "                    (target_sets - target_mean < (i + 1) * target_std)\n",
    "        else:\n",
    "            in_range = (target_sets - target_mean >= i * target_std) & \\\n",
    "                    (target_sets - target_mean <= (i + 1) * target_std)\n",
    "        interval_freq[i-k0] = in_range.sum().item()\n",
    "    node[k] = torch.max(target_sets) \n",
    "    interval_freq = interval_freq / len(target_sets)\n",
    "    \n",
    "    # Step 3: RPWithPrior i.e. Algorithm 1 in this paper\n",
    "    A1, A2 = compute_optimal_interval2(interval_freq, node, epsilon, delta)\n",
    "    while (A2 - A1 < 2 * delta):\n",
    "        print('test')\n",
    "        delta = (A2 - A1) / 2\n",
    "        A1, A2 = compute_optimal_interval2(interval_freq, node, epsilon, delta)\n",
    "    print(torch.min(y_sets),interval_freq, A1, A2, torch.max(y_sets),(y_sets<A1).sum()/len(y_sets), (y_sets>A2).sum()/len(y_sets))\n",
    "    \n",
    "    # Step 4: add noise to target  ##### Algorithm 2 in this paper \n",
    "    # projection by Equation (3.6)  \n",
    "    y_sets1 = y_sets.clone()   \n",
    "    y_sets1[y_sets1 < A1] = A1 \n",
    "    y_sets1[y_sets1 > A2] = A2\n",
    "\n",
    "    rate = 1 / (math.exp(epsilon) *2 * delta + (A2 -A1))\n",
    "    \n",
    "    prob1 = (y_sets1 - A1) * rate \n",
    "    prob1[prob1 < 0] = 0\n",
    "    prob2 = (A2 - y_sets1) * rate \n",
    "    prob2[prob2 < 0] = 0\n",
    "    prob2 = 1- prob2\n",
    "    \n",
    "    new_label = 2 * torch.ones(len(y_sets1), dtype= int).to(device)\n",
    "    random_tensor = torch.rand(len(y_sets1)).to(device)\n",
    "    new_label[random_tensor - prob1 < 0] = 1\n",
    "    new_label[random_tensor - prob2 > 0] = 3\n",
    "    #############################\n",
    "    y_tilde = y_sets1.clone()\n",
    "    \n",
    "    index = new_label == 1\n",
    "    y_tilde[index] = A1 - delta + torch.rand(index.sum()).to(device) * torch.max(\n",
    "        y_sets1[index] - A1,torch.zeros(index.sum()).to(device))\n",
    "    index = new_label == 2\n",
    "    y_tilde[index] = y_sets1[index] + delta * torch.empty_like(y_sets1[index]).uniform_(-1, 1).to(device)\n",
    "    index = new_label == 3\n",
    "    y_tilde[index] = A2 + delta - torch.rand(index.sum()).to(device) * torch.max(\n",
    "        A2 - y_sets1[index],torch.zeros(index.sum()).to(device))\n",
    "    \n",
    "    return x_sets, z_sets, y_sets, y_tilde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., device='cuda:0') tensor([0.6624, 0.1936, 0.0787, 0.0427, 0.0226]) tensor(0.) tensor(78.1321) tensor(400., device='cuda:0') tensor(0., device='cuda:0') tensor(0.3376, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.009615898132324219,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 50,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2ec6431b74e4501ab4b0c2b935574b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40| Train Loss: 1494.77| Train Loss: 8421.65| Test Loss: 8450.46 \n",
      "Epoch: 41| Train Loss: 1472.66| Train Loss: 8239.61| Test Loss: 8270.34 \n",
      "Epoch: 42| Train Loss: 1461.10| Train Loss: 7938.78| Test Loss: 7970.98 \n",
      "Epoch: 43| Train Loss: 1452.30| Train Loss: 7968.97| Test Loss: 8001.23 \n",
      "Epoch: 44| Train Loss: 1445.14| Train Loss: 8001.52| Test Loss: 8033.37 \n",
      "Epoch: 45| Train Loss: 1440.34| Train Loss: 8439.04| Test Loss: 8469.53 \n",
      "Epoch: 46| Train Loss: 1437.48| Train Loss: 8309.90| Test Loss: 8340.82 \n",
      "Epoch: 47| Train Loss: 1433.56| Train Loss: 8181.70| Test Loss: 8211.74 \n",
      "Epoch: 48| Train Loss: 1432.33| Train Loss: 8147.10| Test Loss: 8177.00 \n",
      "Epoch: 49| Train Loss: 1431.48| Train Loss: 8144.66| Test Loss: 8174.73 \n"
     ]
    }
   ],
   "source": [
    "epsilon = 0.05\n",
    "delta = 27\n",
    "\n",
    "model = Net_embedding(vocab_size=dataset.get_vocab()).to(device)\n",
    "\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50, eta_min=5e-6)\n",
    "\n",
    "loss_func = torch.nn.MSELoss()\n",
    "epoch = 50\n",
    "batch_size = 8192\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
    "      shuffle=True, num_workers=8, pin_memory=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, \n",
    "      shuffle=True, num_workers=6, pin_memory=True)\n",
    "\n",
    "# Train                                      \n",
    "x_sets, z_sets, y_sets, y_tilde = RPWithPrior3(train_loader, device, epsilon= epsilon, delta=delta)\n",
    "\n",
    "# Train the model with the Label-DP dataset\n",
    "labeldp_dataset = torch.utils.data.TensorDataset(x_sets.detach().cpu(),\n",
    "                    z_sets.detach().cpu(), y_tilde.detach().cpu())\n",
    "labeldp_loader = torch.utils.data.DataLoader(labeldp_dataset,\n",
    "            batch_size=batch_size, shuffle=True, num_workers=6, pin_memory=True)\n",
    "for i in tqdm(range(epoch)):\n",
    "    losses = AverageMeter()\n",
    "    for j, (x, z, y) in enumerate(labeldp_loader):\n",
    "        x, z, y = x.to(device), z.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x, z)\n",
    "        loss = loss_func(output.view(-1), y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.update(loss.item(), x.shape[0])\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    if i >=40: \n",
    "        train_loss = AverageMeter()\n",
    "        test_loss = AverageMeter()\n",
    "        with torch.no_grad():\n",
    "            for x, z, y in train_loader:\n",
    "                x, z, y = x.to(device), z.to(device), y.to(device)\n",
    "                output = model(x, z)\n",
    "                loss = loss_func(output.view(-1), y)\n",
    "                train_loss.update(loss.item(), x.shape[0])\n",
    "            for x, z, y in test_loader:\n",
    "                x, z, y = x.to(device), z.to(device), y.to(device)\n",
    "                output = model(x, z)\n",
    "                loss = loss_func(output.view(-1), y)\n",
    "                test_loss.update(loss.item(), x.shape[0])\n",
    "        print(\"Epoch: {:>2}| Train Loss: {:.2f}| Train Loss: {:.2f}| Test Loss: {:.2f} \".format(i, \n",
    "                    losses.avg, train_loss.avg, test_loss.avg))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mytorch1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
